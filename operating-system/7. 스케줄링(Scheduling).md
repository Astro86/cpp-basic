# 7. 스케줄링(Scheduling)
  - CPU 스케줄링 : 다중 프로그램 운영체제의 기본.
  - OS는 프로세스들 간에 CPU를 교환함으로써 CPU 이용률을 최대화하여 컴퓨터를 보다 생산적으로 만든다.
  - CPU를 사용하는 패턴이 서로 다른 여러 프로그램이 동일한 시스템 내부에서 함께 실행되기 때문에 필요하다.
   
### 7.0.1 CPU 버스트 & I/O 버스트(CPU Burst & I/O Burst)
  - 프로세스들은 CPU 버스트와 I/O 버스트의 사이클로 구성된다.
  - CPU 버스트 : 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 단계
  - I/O 버스트 : I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 비교적 느린 단계
  - 프로레스의 실행은 CPU 버스트(burst)로 시작된다. 뒤이어 I/O 버스트가 발생하고 이 둘이 반복된다.
  
![image20](https://user-images.githubusercontent.com/35681772/59988651-d4ae2280-9676-11e9-9318-ae471b1351ec.jpg)

### 7.0.2 CPU 바운드 프로세스 & I/O 바운드 프로세스(CPU Bound Process & I/O Bound Process)
  - CPU 바운드 프로세스 : I/O작업을 거의 수행하지 않아 CPU 버스트가 길게 나타나는 프로세스
  - I/O 바운드 프로세스 : I/O요청이 빈번해 CPU 버스트가 짧게 나타나는 프로세스. 대부분 대화형 작업(interactive job)으로 사용자와 interaction 해가며 프로그램을 수행시킨다.
    
![image21](https://user-images.githubusercontent.com/35681772/59988661-dc6dc700-9676-11e9-9210-a130a3c9133c.jpg)

### 7.0.3 CPU 스케줄러
  - CPU 스케줄러 : 준비 상태에 있는 프로세스들 중 어떤 프로세스에게 CPU를 할당할지를 결정하는 OS의 코드.
  - 한 프로세스가 CPU를 할당받고 기계어 명령을 수행하다 타이머 인터럽트(timer interrupt)가 발생하면 CPU 스케줄러가 호출된다. 그러면 CPU 스케줄러는 준비 큐(ready queue)에서 CPU를 기다리는 프로세스들 중 하나를 선택해 CPU를 할당하게 된다.
  - CPU 스케줄링의 방식엔 두가지가 있다.
    - 비선점형(nonpreemptive) 방식 : CPU를 획득한 프로세스가 스스로 CPU를 반납하기 전까지는 CPU를 빼앗기지 않는 방법.
      - 예시1) 실행 상태에 있던 프로세스가 I/O 요청 등에 의해 봉쇄(blocked) 상태로 바뀌는 경우
      - 예시2) CPU에서 실행 상태에 있는 프로세스가 종료되는 경우
    - 선점형(preemptive) 방식 : 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링 방법.
      - 예시1) 실행 상태에 있던 프로세스가 타이머 인터럽트 발생에 의해 준비 상태로 바뀌는 경우
      - 예시2) I/O요청으로 봉쇄 상태에 있던 프로세스의 I/O작업이 완료되어 인터럽트가 발생하고 그 결과 이 프로세스의 상태가 준비 상태로 바뀌는 경우

### 7.0.4 디스패처(dispatcher)
  - 디스패처 : 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경 설정을 하는 커널 모듈.
  - 디스패처는 현재 수행중이던 프로세스의 문맥(context)을 그 프로세스의 PCB에 저장하고, 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한 후 그 프로세스에게 CPU를 넘기는 과정을 수행.
  
![image1](https://user-images.githubusercontent.com/35681772/59988673-e7c0f280-9676-11e9-87cb-3d3c99a8322d.jpg)

  - PCB(Process Control Block) : OS 커널의 자료구조. 특정 프로세스의 스케줄링에 필요로 하는 정보를 담고 있음.
  
  - 디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연 시간(dispatch latency)이라 부르는데 이는 context switching overhead에 해당된다.

---

## 7.1 워크로드에 대한 가정

워크로드(workload) : 일련의 프로세스들이 실행하는 상황을 의미. 단계별로 결론을 도출해 내기위해 워크로드에 대한 가정이 필요한데 그 내용은 다음과 같다.

  - 모든 작업은 같은 시간 동안 실행된다.
  - 모든 작업은 동시에 도착한다.
  - 각 작업은 시작되면 완료될 때까지 실행된다.
  - 모든 작업은 CPU만 사용한다(즉, I/O를 수행하지 않는다).
  - 각 작업의 실행 시간은 사전에 알려져 있다.

이런 가정들을 하나씩 해제하며 결론에 도달해 본다.

---

## 7.2 스케줄링 평가 항목
스케줄링 정책의 비교를 위해 스케줄링 평가 항목을 결정해야 하는데, 다음과 같은 것들이 이 평가항목에 포함된다.

![image058](https://user-images.githubusercontent.com/35681772/59988718-18a12780-9677-11e9-9944-b22bddb69ffe.png)

  - **반환 시간(turnaround time)** : 성능 측면에서의 평가기준. 작업이 완료된 시간에서 시스템에 도착한 시각을 뺀 시간이다. 
  - 공정성(fairness) : 성능(소요시간)과 상충되는 평가기준.

turnaround_time : 작업이 완료된 시간 - 작업이 도착한 시간
response_time : 작업 시작된 시간 - 작업이 도착한 시간

---

---

## 7.3 선입선출(First In First Out, FIFO) 스케줄링
FIFO 스케줄링의 문제점으로는 **Convoy effect** 가 있다. Convoy effect란 *짧은 시간동안 리소스를 사용 할 프로세스들이 오랜 시간동안 리소스를 사용하는 프로세스가 종료될 때 까지 대기하여 비효율이 발생하는 현상* 을 말한다.
 
![image4](https://user-images.githubusercontent.com/35681772/59988772-45553f00-9677-11e9-92d8-9ec193e76e89.jpg)

여기서 첫번째 가정을 완화하여 작업 실행 시간이 모두 같지 않을 경우 위와같은 순서로 프로세스가 처리된다. 이게 바로 convoy effect다.

작업 실행 순서는 A → B → C 가 된다.

이 때, 평균 반환 시간(turnaround time) = (100 + 110 + 120) / 3 = 110

---

 ## 7.4 최단 작업 우선(Shortest Job First, SJF) 스케줄링 : 소요시간↑, 응답시간↓

**가장 짧은 실행시간을 가진 프로세스를 먼저 실행**시킨다.

![image059](https://user-images.githubusercontent.com/35681772/59988787-50a86a80-9677-11e9-8380-3965848e79c6.jpg)

작업 실행 순서는 B → C  → A 가 된다.

이 때, 평균 반환 시간은 모든 작업이 동시에 도착했다고 가정하였으므로, (10 - 0) + (20 - 0) + (120 - 0) / 3 = 50

그러나 가정 하나를 완화하여 모든 작업이 동시에 도착하지 않는다면? 

![img1](https://user-images.githubusercontent.com/35681772/59988796-58680f00-9677-11e9-8a44-f1c3242128e0.png)

만약 B와 C가 A보다 늦게 도착하는 경우(A의 arrival time T = 0, B의 T = 10, C의 T = 10) 다시 Convoy 문제가 발생한다. 

이 때, 평균 반환 시간은 (100 - 0) + (110 - 10) + (120 - 10) / 3 = 103.33

---

## 7.5 최소 잔여시간 우선(Shortest Time-to-Completion First, STCF) 스케줄링 : 소요시간↑, 응답시간↓

언제든 *새로운 작업이 시스템에 들어오면 남아있는 작업과 새로운 작업의 잔여 실행시간을 계산하여* **가장 적은 실행시간의 작업을 먼저 스케줄링** 하는 것. 위 SJF에 선점 기능(OS가 CPU를 뺏어오는 것)을 추가한 것이 STCF 이다.

세번째 가정을 없애 각 작업은 도중에 Context Switching이 일어날 수 있는 상황에서 STCF를 계산해보자.

![image5](https://user-images.githubusercontent.com/35681772/59988803-66b62b00-9677-11e9-831c-5545f7ffeb24.jpg)

작업 순서는 A → B → C → A 순서이며, A 실행 도중 작업량이 더 짧은 B와 C가 들어왔으므로 B와 C를 먼저 끝날때 까지 실행시킨다. 두 작업이 모두 끝난 후에 A를 남은 시간만큼 실행시킨다.

이 때, 평균 반환 시간 = ((120 - 0) + (20 - 10) + (30 - 10)) / 3 = 50

---

## 7.6 새로운 평가 기준 : 응답 시간(Response Time)
새로운 컴퓨터가 등장하여 사용자는 시스템에게 *상호작용(interaction)* 을 원활히 하기위한 성능을 요구하게 되면서 *응답시간* 이라는 새로운 평가기준이 나타났다.

**응답 시간** 이란 작업이 도착할 때 부터 처음 스케줄 될 때 까지의 시간.
  
![image6](https://user-images.githubusercontent.com/35681772/59988818-72095680-9677-11e9-8eac-2fd304360a9d.jpg)

위의 STCF를 포함한 policy들은 응답시간이 짧다고 할 수 없다. 3개의 작업이 동시에 도착한 경우, 세번째 작업은 먼저 실행된 두 작업이 먼저 스케줄되기 때문에 끝날때 까지 기다려야만 함.

위 STCF 예에서의 스케줄(A 도착시간 : 0, B 도착시간 : 10, C 도착시간 : 10)의 경우 응답 시간은 (0 - 0) + (10 - 10) + (20 - 10) / 3 = 3.33 이 된다.

---

## 7.7 라운드 로빈(Round-Robin, RR) 스케줄링(a.k.a. 타임 슬라이싱) : 응답시간↑, 소요시간↓
응답시간(Response Time)에 민감한 스케줄러가 필요해서 등장하였다. *라운드 로빈* 방법은 작업이 끝날 때 까지 기다리지 않고 "일정 시간(time-slice)" 후 실행 큐의 다음 작업으로 전환. 여기서 작업이 실행되는 "일정 시간" 을 **타임 슬라이스(Time Slice)** 또는 **스케줄링 퀀텀(Scheduling Quantum)** 이라 부른다.

![image7](https://user-images.githubusercontent.com/35681772/59988830-7cc3eb80-9677-11e9-8c62-ac1d2130256e.jpg)
 
위 경우 A, B, C가 0초에 동시 도착하고 모두 5의 작업량을 갖는 경우

SJF의 평균 응답 시간 = (0 - 0) + (5 - 0) + (10 - 0) / 3 = 5 가 되고 RR의 평균 응답 시간 = (0 - 0) + (1 - 0) + (2 - 0) / 3 = 1 이 된다.

타임 슬라이스가 짧을수록 RR의 성능은 더 좋아진다. *그러나 너무 짧을 경우 context switching에 소요되는 cost가 전체 성능에 영향을 미치기 때문에 퍼포먼스가 떨어지게 된다.* 따라서 둘 사이의 최적점을 찾아야한다.

Context Switching에 소요되는 cost로는 레지스터 저장/복원 + CPU 캐시, TLB 등 다른 하드웨어의 프로그램 관련 작업정보 갱신 등 매우 큰 성능 cost를 유발한다.

RR의 경우 응답 시간(response time)을 기준으로 평가해보면 매우 괜찮은 스케줄러지만, 반환 시간(turnaround time)을 기준으로 생각해보면 매우 안좋은 스케줄러다. RR은 각 작업을 분할하여 실행하므로 작업을 늘리는것이 목표이기 때문.

---

## 7.8 입출력 연산의 고려

입출력(I/O) 작업이 요청된 경우 현재 실행중인 작업은 I/O 연산이 완료될 때 까지 CPU를 사용할 수 없으므로 스케줄러는 다음에 어떤 작업을 실행할 지 결정해야 한다.
  
I/O 요청을 발생시킨 작업은 입출력 작업이 완료되기를 기다리며 대기 상태가 된다. 스케줄러는 이 시간동안 실행될 다른 작업을 스케줄 해야 한다. 
 
![image8](https://user-images.githubusercontent.com/35681772/59988844-89484400-9677-11e9-965d-0a77b0f02bc2.jpg)

위 예시에서 A와 B는 50msec의 CPU시간을 필요로 하고, A는 매 10msec 실행 후 I/O를 필요로 한다면 A의 I/O 동안 CPU가 아무 일을 안하고 놀게될 수 있다.

이 상황은 STCF 스케줄러에 의해 *A의 매 10msec 당 작업을 하나의 독립적인 작업으로 간주하여 A의 10msec 이후 I/O를 요청하는 동안 하나의 작업이 끝난 것으로 간주하여 B를 10msec(A의 I/O 동안) 수행하고, 그 다음 A의 또 다른 10msec의 작업을 수행하는 식으로의 '중첩'을 통해 CPU를 효율적으로 사용이 가능하다.

스케줄러는 위와같이 한 프로세스의 I/O가 끝나기를 기다리는 동안 CPU는 다른 프로세스에 의해 사용되어 작업들을 겹쳐서 연산 될 수 있게 해 준다. 이렇게 하여 CPU의 이용률을 더 높힐 수 있게 된다.

---

## 7.9 & 7.10 마무리
앞서 언급한 SJF 나 STCF 같은 알고리즘의 경우 스케줄러가 각 작업의 실행 시간을 알고 있다고 가정한 채 적용되었고 이는 사실상 불가능하다. 

스케줄링의 기본개념 두가지는 다음과 같다.
  - 남아있는 작업 중 실행 시간이 제일 짧은 작업을 수행하고 *소요시간을 최소화* 하는 방법
  - 모든 작업을 번갈아 실행시키고 *응답시간을 최소화* 하는 방법

소요시간(turnaround time)과 응답시간(response time)은 서로 상충관계(trade-off)에 있다.

따라서 **가까운 과거의 이벤트를 이용하여 미래를 예측하는 '멀티 레벨 피드백 큐(Multi-Level Feedback Queue)' 스케줄러**를 구현하여 이와같은 문제들을 해결하게 된다.

![img2](https://user-images.githubusercontent.com/35681772/59988867-9b29e700-9677-11e9-9d8c-d7b1b91e4ed9.png)


---